{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq0xmIsJPk0B",
        "outputId": "b0459176-a374-4880-b44a-1dd5a57e02a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/uciml/adult-census-income\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH2caD-YQSIR",
        "outputId": "8470cf18-2c71-4a7c-d4c9-ff5696d2a9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OYjYI-mzPcXR"
      },
      "outputs": [],
      "source": [
        " #--- 1. Setup, Imports, and Data Loading ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "COLUMNS = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
        "]\n",
        "\n",
        "# Note: You will need to place the 'adult.csv' file in the same directory (or upload it to Colab).\n",
        "    # IMPORTANT: The next line is how you typically load data in Colab after uploading the file\n",
        "data = pd.read_csv(\n",
        "    '/content/adult-census-income/adult.csv',\n",
        "    header=0, # Set header to 0 to use the first row as header\n",
        "    names=COLUMNS,\n",
        "    skipinitialspace=True,\n",
        "    # Remove the next line to avoid duplicating the header row in the data\n",
        "    # header=None,\n",
        ")\n",
        "\n",
        "data.drop_duplicates(inplace=True)\n",
        "print(f\"Data loaded successfully. Total records after cleaning: {len(data)}\")\n",
        "print(\"Initial Data Head:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "5Fo5YrHuQoeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  Feature and Target Separation ---\n",
        "le = LabelEncoder()\n",
        "data['income_encoded'] = le.fit_transform(data['income'])\n",
        "\n",
        "y = data['income_encoded']\n",
        "X = data.drop(['income', 'income_encoded'], axis=1)\n",
        "\n",
        "# Define feature types based on current dtypes\n",
        "NUMERICAL_FEATURES = X.select_dtypes(include=np.number).columns.tolist()\n",
        "CATEGORICAL_FEATURES = X.select_dtypes(include='object').columns.tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "U81BEcS6RzmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "id": "wZgo-kKoT-B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Manual Preprocessing (Impute, Scale, and Encode) ---\n",
        "\n",
        "print(\"\\n--- Step 3: Manual Preprocessing (Imputing, Scaling & Encoding) ---\")\n",
        "\n",
        "# A. Impute Missing Values (AFTER splitting to prevent data leakage)\n",
        "# Impute Numerical Features with the mean (fit only on X_train)\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "X_train[NUMERICAL_FEATURES] = num_imputer.fit_transform(X_train[NUMERICAL_FEATURES])\n",
        "X_test[NUMERICAL_FEATURES] = num_imputer.transform(X_test[NUMERICAL_FEATURES])\n",
        "\n",
        "# Impute Categorical Features with the mode (fit only on X_train)\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train[CATEGORICAL_FEATURES] = cat_imputer.fit_transform(X_train[CATEGORICAL_FEATURES])\n",
        "X_test[CATEGORICAL_FEATURES] = cat_imputer.transform(X_test[CATEGORICAL_FEATURES])\n",
        "\n",
        "\n",
        "# B. One-Hot Encode Categorical Features\n",
        "# Instantiate the encoder and fit ONLY on the training data\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "ohe.fit(X_train[CATEGORICAL_FEATURES])\n",
        "\n",
        "# Transform both training and testing data\n",
        "X_train_cat_encoded = pd.DataFrame(ohe.transform(X_train[CATEGORICAL_FEATURES]), columns=ohe.get_feature_names_out(CATEGORICAL_FEATURES), index=X_train.index)\n",
        "X_test_cat_encoded = pd.DataFrame(ohe.transform(X_test[CATEGORICAL_FEATURES]), columns=ohe.get_feature_names_out(CATEGORICAL_FEATURES), index=X_test.index)\n",
        "\n",
        "# C. Scale Numerical Features\n",
        "# Instantiate the scaler and fit ONLY on the training data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[NUMERICAL_FEATURES])\n",
        "\n",
        "# Transform both training and testing data\n",
        "X_train_num_scaled = pd.DataFrame(scaler.transform(X_train[NUMERICAL_FEATURES]), columns=NUMERICAL_FEATURES, index=X_train.index)\n",
        "X_test_num_scaled = pd.DataFrame(scaler.transform(X_test[NUMERICAL_FEATURES]), columns=NUMERICAL_FEATURES, index=X_test.index)\n",
        "\n",
        "# D. Combine the processed features back into the final training/testing sets\n",
        "X_train_final = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis=1)\n",
        "X_test_final = pd.concat([X_test_num_scaled, X_test_cat_encoded], axis=1)\n",
        "\n",
        "print(f\"Final training feature shape: {X_train_final.shape}\")\n",
        "print(f\"Final testing feature shape: {X_test_final.shape}\")"
      ],
      "metadata": {
        "id": "dmas6W1fa_E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Model Training and Comparison ---\n",
        "\n",
        "trained_models = {}\n",
        "all_metrics = []\n",
        "\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
        "\n",
        "    print(f\"\\n--- Training {model_name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[model_name] = model\n",
        "\n",
        "    # Make predictions and calculate metrics\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Check if the model has predict_proba, otherwise use predict output\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        # Fallback for models without predict_proba (like some SVM configurations)\n",
        "        y_proba = y_pred\n",
        "\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # Handle the case where y_test contains only one class for roc_auc_score\n",
        "    if len(np.unique(y_test)) > 1:\n",
        "        roc_auc = roc_auc_score(y_test, y_proba)\n",
        "    else:\n",
        "        roc_auc = np.nan # Or some other indicator that ROC AUC is not applicable\n",
        "\n",
        "\n",
        "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    # Focus on the metrics for the minority class (>50K)\n",
        "    print(\"\\nClassification Report (Focus on Precision/Recall for >50K):\")\n",
        "    report = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'], output_dict=True)\n",
        "    print(classification_report(y_test, y_pred, target_names=['<=50K', '>50K']))\n",
        "\n",
        "    # Return key metrics for comparison\n",
        "    return {'model': model_name, 'accuracy': accuracy, 'roc_auc': roc_auc, 'f1_50k_plus': report['>50K']['f1-score']}"
      ],
      "metadata": {
        "id": "7SdiOpE9UGfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression\n",
        "lr_model = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced', max_iter=1000)\n",
        "metrics_lr = train_and_evaluate_model(lr_model, X_train_final, y_train, X_test_final, y_test, \"Logistic Regression\")\n",
        "all_metrics.append(metrics_lr)\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(metrics_lr)"
      ],
      "metadata": {
        "id": "3aJw3KaOb9-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42, class_weight='balanced')\n",
        "metrics_dt = train_and_evaluate_model(dt_model, X_train_final, y_train, X_test_final, y_test, \"Decision Tree Classifier\")\n",
        "all_metrics.append(metrics_dt)\n",
        "print(\"Decision Tree Classifier Metrics:\")\n",
        "print(metrics_dt)"
      ],
      "metadata": {
        "id": "fU0rXHZucFFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Comparison and Best Model Selection\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL MODEL PERFORMANCE COMPARISON TABLE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "comparison_df = pd.DataFrame(all_metrics).set_index('model').sort_values(by='roc_auc', ascending=False)\n",
        "print(comparison_df)\n",
        "\n",
        "best_model_name = comparison_df.iloc[0].name\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(f\"\\n--> The BEST performing model (based on ROC AUC) is: {best_model_name}\")"
      ],
      "metadata": {
        "id": "zMc2iwqVcK7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Custom Prediction (Answering the Problem Statement) ---\n",
        "\n",
        "# Note: We can't easily predict a single raw dictionary with this manual method.\n",
        "# To predict a new person, we must manually transform their features using the\n",
        "# fitted scaler and OHE objects.\n",
        "\n",
        "def predict_new_income_manual(model, new_data):\n",
        "    \"\"\"Predicts income class for a single new record using the best model and manual transformers.\"\"\"\n",
        "\n",
        "    # 1. Convert dictionary into a DataFrame (ensuring correct order)\n",
        "    new_df = pd.DataFrame([new_data], columns=X.columns)\n",
        "\n",
        "    # Ensure categorical columns are of 'object' dtype to prevent TypeError with isnan check in OneHotEncoder\n",
        "    for col in CATEGORICAL_FEATURES:\n",
        "        new_df[col] = new_df[col].astype('object')\n",
        "\n",
        "\n",
        "    # 2. Separate numerical and categorical parts\n",
        "    new_num = new_df[NUMERICAL_FEATURES]\n",
        "    new_cat = new_df[CATEGORICAL_FEATURES]\n",
        "\n",
        "    # 3. Apply the fitted transformers to the new data\n",
        "    new_num_scaled = pd.DataFrame(scaler.transform(new_num), columns=NUMERICAL_FEATURES)\n",
        "    new_cat_encoded = pd.DataFrame(ohe.transform(new_cat), columns=ohe.get_feature_names_out(CATEGORICAL_FEATURES))\n",
        "\n",
        "    # 4. Combine and finalize the feature set\n",
        "    X_new_final = pd.concat([new_num_scaled, new_cat_encoded], axis=1)\n",
        "\n",
        "    # 5. Make prediction\n",
        "    prediction_class = model.predict(X_new_final)[0]\n",
        "    prediction_proba = model.predict_proba(X_new_final)[0][1]\n",
        "\n",
        "    # 6. Interpret result\n",
        "    income_map = {0: '<=50K', 1: '>50K'}\n",
        "    predicted_income = income_map[prediction_class]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"PREDICTION RESULT (Using {best_model_name}):\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Predicted Income Class: {predicted_income}\")\n",
        "    print(f\"Probability of earning >$50K: {prediction_proba:.2f}\")\n",
        "\n",
        "# Example input for a new, single individual:\n",
        "sample_person = {\n",
        "    'age': 45,\n",
        "    'workclass': 'Private',\n",
        "    'fnlwgt': 140359, # Added missing column with example value\n",
        "    'education': 'Bachelors', # Added missing column with example value\n",
        "    'education-num': 14,\n",
        "    'marital-status': 'Married-civ-spouse',\n",
        "    'occupation': 'Exec-managerial',\n",
        "    'relationship': 'Husband',\n",
        "    'race': 'White',\n",
        "    'sex': 'Male',\n",
        "    'capital-gain': 5000,\n",
        "    'capital-loss': 0,\n",
        "    'hours-per-week': 50,\n",
        "    'native-country': 'United-States',\n",
        "}\n",
        "\n",
        "# Run the prediction function with the best model\n",
        "predict_new_income_manual(best_model, sample_person)"
      ],
      "metadata": {
        "id": "51giBpVYcPQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Visualization and Reporting ---\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- Step 6: Visualization and Reporting ---\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. ROC AUC Comparison Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(\n",
        "    x=comparison_df.index,\n",
        "    y=comparison_df['roc_auc'],\n",
        "    hue=comparison_df.index,  # Assign x to hue\n",
        "    palette='viridis',\n",
        "    legend=False  # Set legend to False as suggested by the warning\n",
        ")\n",
        "plt.title('Model Performance Comparison (ROC AUC Score)')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.xlabel('Model')\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 2. Confusion Matrix for the Best Model\n",
        "# Assuming best_y_pred is available from a previous step (e.g., prediction on test set)\n",
        "# If not, you would need to generate it here:\n",
        "best_y_pred = best_model.predict(X_test_final)\n",
        "cm = confusion_matrix(y_test, best_y_pred)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=['Actual <=50K', 'Actual >50K'],\n",
        "    columns=['Predicted <=50K', 'Predicted >50K']\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm_df,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=False,\n",
        "    linecolor='black',\n",
        "    linewidths=0.5\n",
        ")\n",
        "plt.title(f'Confusion Matrix for {best_model_name}')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v5w9QOr3jePU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}